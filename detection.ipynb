{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from patches import Patches, PatchEncoder\n",
    "from hyperparameters import *\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "if os.path.exists('config/localconfig.py'):\n",
    "    from config import localconfig as config\n",
    "else:\n",
    "    from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "    f for f in os.listdir(config.BB_IMAGES) if os.path.isfile(os.path.join(config.BB_IMAGES, f))\n",
    "]\n",
    "\n",
    "import random\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "images, targets = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000 # target is len(image_paths)\n",
    "\n",
    "for i in range(0, size):\n",
    "    # Print progress\n",
    "    if i % (size / 100) == 0:\n",
    "        print(f'Proceeded {int((i / size) * 100)}%')\n",
    "\n",
    "    image = keras.utils.load_img(os.path.join(config.BB_IMAGES, image_paths[i]))\n",
    "    w, h = image.size[:2]\n",
    "\n",
    "    # resize training set\n",
    "    if i < int(size * 0.8):\n",
    "        image = image.resize((image_size, image_size))\n",
    "    images.append(keras.utils.img_to_array(image))\n",
    "    del image\n",
    "    gc.collect()\n",
    "\n",
    "    with open(os.path.join(config.BB_ANNOTATIONS, f'{image_paths[i]}.json')) as f:\n",
    "        annot = json.load(f)\n",
    "\n",
    "    target = []\n",
    "    for i in range(len(annot['objects'])):\n",
    "        coords = annot['objects'][i]['points']['exterior']\n",
    "        top_left_x, top_left_y = coords[0][0], coords[0][1]\n",
    "        bottom_right_x, bottom_right_y = coords[1][0], coords[1][1]\n",
    "        target.append((float(top_left_x) / w,\n",
    "                       float(top_left_y) / h,\n",
    "                       float(bottom_right_x) / w,\n",
    "                       float(bottom_right_y) / h))\n",
    "        del coords, top_left_x, top_left_y, bottom_right_x, bottom_right_y\n",
    "        gc.collect()\n",
    "    del annot\n",
    "    gc.collect()\n",
    "\n",
    "    target = sorted(target, key=lambda x: abs((x[2] - x[0]) * (x[3] - x[1])), reverse=True)\n",
    "\n",
    "    if len(target) > 0:\n",
    "        targets.append(target[0])\n",
    "    else:\n",
    "        images.pop()\n",
    "    \n",
    "    del target\n",
    "    gc.collect()\n",
    "\n",
    "del image_paths\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train), (y_train) = (\n",
    "    np.asarray(images[: int(len(images) * 0.8)]),\n",
    "    np.asarray(targets[: int(len(targets) * 0.8)]),\n",
    ")\n",
    "(x_test), (y_test) = (\n",
    "    np.asarray(images[int(len(images) * 0.8) :]),\n",
    "    np.asarray(targets[int(len(targets) * 0.8) :]),\n",
    ")\n",
    "del images, targets\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(x_train[0].astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "patches = Patches(patch_size)(tf.convert_to_tensor([x_train[0]]))\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"{patches.shape[1]} patches per image \\n{patches.shape[-1]} elements per patch\")\n",
    "\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_vit_object_detector(\n",
    "    input_shape,\n",
    "    patch_size,\n",
    "    num_patches,\n",
    "    projection_dim,\n",
    "    num_heads,\n",
    "    transformer_units,\n",
    "    transformer_layers,\n",
    "    mlp_head_units,\n",
    "):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    # Encode patches\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.3)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.3)\n",
    "\n",
    "    bounding_box = layers.Dense(4)(\n",
    "        features\n",
    "    )  # Final four neurons that output bounding box\n",
    "\n",
    "    # return Keras model.\n",
    "    return keras.Model(inputs=inputs, outputs=bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model: tf.keras.Model, learning_rate, weight_decay, batch_size, num_epochs):\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Compile model.\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=keras.losses.MeanSquaredError(),\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    checkpoint_filepath = \"logs/\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[\n",
    "            checkpoint_callback,\n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "vit_object_detector = create_vit_object_detector(\n",
    "    input_shape,\n",
    "    patch_size,\n",
    "    num_patches,\n",
    "    projection_dim,\n",
    "    num_heads,\n",
    "    transformer_units,\n",
    "    transformer_layers,\n",
    "    mlp_head_units,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = run_experiment(\n",
    "    vit_object_detector, learning_rate, weight_decay, batch_size, num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the model in current path\n",
    "vit_object_detector.save(f\"vit_object_detector_{int(time.time())}.h5\", save_format=\"h5\")\n",
    "\n",
    "# To calculate IoU (intersection over union, given two bounding boxes)\n",
    "def bounding_box_intersection_over_union(box_predicted, box_truth):\n",
    "    # get (x, y) coordinates of intersection of bounding boxes\n",
    "    top_x_intersect = max(box_predicted[0], box_truth[0])\n",
    "    top_y_intersect = max(box_predicted[1], box_truth[1])\n",
    "    bottom_x_intersect = min(box_predicted[2], box_truth[2])\n",
    "    bottom_y_intersect = min(box_predicted[3], box_truth[3])\n",
    "\n",
    "    # calculate area of the intersection bb (bounding box)\n",
    "    intersection_area = max(0, bottom_x_intersect - top_x_intersect + 1) * max(\n",
    "        0, bottom_y_intersect - top_y_intersect + 1\n",
    "    )\n",
    "\n",
    "    # calculate area of the prediction bb and ground-truth bb\n",
    "    box_predicted_area = (box_predicted[2] - box_predicted[0] + 1) * (\n",
    "        box_predicted[3] - box_predicted[1] + 1\n",
    "    )\n",
    "    box_truth_area = (box_truth[2] - box_truth[0] + 1) * (\n",
    "        box_truth[3] - box_truth[1] + 1\n",
    "    )\n",
    "\n",
    "    # calculate intersection over union by taking intersection\n",
    "    # area and dividing it by the sum of predicted bb and ground truth\n",
    "    # bb areas subtracted by  the interesection area\n",
    "\n",
    "    # return ioU\n",
    "    return intersection_area / float(\n",
    "        box_predicted_area + box_truth_area - intersection_area\n",
    "    )\n",
    "\n",
    "\n",
    "i, mean_iou = 0, 0\n",
    "\n",
    "# Compare results for 10 images in the test set\n",
    "for input_image in x_test[:10]:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 15))\n",
    "    im = input_image\n",
    "\n",
    "    # Display the image\n",
    "    ax1.imshow(im.astype(\"uint8\"))\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(im.astype(\"uint8\"))\n",
    "    ax2.axis('off')\n",
    "\n",
    "    input_image = cv2.resize(\n",
    "        input_image, (image_size, image_size), interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "    input_image = np.expand_dims(input_image, axis=0)\n",
    "    preds = vit_object_detector.predict(input_image)[0]\n",
    "\n",
    "    (h, w) = (im).shape[0:2]\n",
    "\n",
    "    top_left_x, top_left_y = int(preds[0] * w), int(preds[1] * h)\n",
    "\n",
    "    bottom_right_x, bottom_right_y = int(preds[2] * w), int(preds[3] * h)\n",
    "\n",
    "    box_predicted = [top_left_x, top_left_y, bottom_right_x, bottom_right_y]\n",
    "    # Create the bounding box\n",
    "    rect = matplotlib.patches.Rectangle(\n",
    "        (top_left_x, top_left_y),\n",
    "        bottom_right_x - top_left_x,\n",
    "        bottom_right_y - top_left_y,\n",
    "        facecolor=\"none\",\n",
    "        edgecolor=\"red\",\n",
    "        linewidth=1,\n",
    "    )\n",
    "    # Add the bounding box to the image\n",
    "    ax1.add_patch(rect)\n",
    "    ax1.set_title('Detected bounding box')\n",
    "    ax1.set_xlabel(\n",
    "        f\"Predicted: ({top_left_x}, {top_left_y}), ({bottom_right_x}, {bottom_right_y})\")\n",
    "\n",
    "    top_left_x, top_left_y = int(y_test[i][0] * w), int(y_test[i][1] * h)\n",
    "\n",
    "    bottom_right_x, bottom_right_y = int(y_test[i][2] * w), int(y_test[i][3] * h)\n",
    "\n",
    "    box_truth = top_left_x, top_left_y, bottom_right_x, bottom_right_y\n",
    "\n",
    "    mean_iou += bounding_box_intersection_over_union(box_predicted, box_truth)\n",
    "    # Create the bounding box\n",
    "    rect = matplotlib.patches.Rectangle(\n",
    "        (top_left_x, top_left_y),\n",
    "        bottom_right_x - top_left_x,\n",
    "        bottom_right_y - top_left_y,\n",
    "        facecolor=\"none\",\n",
    "        edgecolor=\"red\",\n",
    "        linewidth=1,\n",
    "    )\n",
    "    # Add the bounding box to the image\n",
    "    ax2.add_patch(rect)\n",
    "    ax2.set_title('The largest bounding box')\n",
    "    ax2.set_xlabel(\n",
    "        f\"Target: ({top_left_x}, {top_left_y}), ({bottom_right_x}, {bottom_right_y})\\nIoU{bounding_box_intersection_over_union(box_predicted, box_truth)})\"\n",
    "    )\n",
    "    i = i + 1\n",
    "\n",
    "print(\"mean_iou: \" + str(mean_iou / len(x_test[:10])))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c013d6d5eb5ad4ebcf3fbdc592eb4746d753f59595d37b4a7d1710f37ceaed5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
